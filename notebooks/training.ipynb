{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the previous directory to the Python path\n",
    "previous_directory = os.path.abspath(os.path.join(os.getcwd(), os.pardir))\n",
    "if previous_directory not in sys.path:\n",
    "    sys.path.append(previous_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from model.model import NeuralProbabilisticLanguageModel\n",
    "from data_loader.data_loaders import NGramDataLoader\n",
    "from data_loader.data_loaders import collate_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n"
     ]
    }
   ],
   "source": [
    "data_dir = \"../_data/raw/ptwiki-latest-pages-articles\"  # Update this path as needed\n",
    "batch_size = 512\n",
    "embedding_dim = 100\n",
    "hidden_dim = 128\n",
    "learning_rate = 0.001\n",
    "num_epochs = 10\n",
    "n = 3  # Trigram\n",
    "load_fraction = 0.01\n",
    "random_load = True\n",
    "vocab_size = 10000  # Must match the NGramDataset's vocab_size\n",
    "num_workers = 4  # Adjust based on your system\n",
    "\n",
    "# Device configuration\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocabulary Size: 10000\n"
     ]
    }
   ],
   "source": [
    "# Initialize DataLoader\n",
    "\n",
    "dataloader = NGramDataLoader(\n",
    "    data_dir=data_dir,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    num_workers=num_workers,\n",
    "    n=n,\n",
    "    load_fraction=load_fraction,\n",
    "    random_load=random_load,\n",
    "    vocab_size=vocab_size\n",
    ")\n",
    "\n",
    "# Access the dataset and vocabulary\n",
    "dataset = dataloader.dataset\n",
    "\n",
    "# Check if the dataset is empty\n",
    "if len(dataset) == 0:\n",
    "    raise ValueError(\"The dataset is empty. Please check the data directory and loading parameters.\")\n",
    "\n",
    "word_to_index = dataset.get_word_to_index()\n",
    "actual_vocab_size = len(word_to_index)\n",
    "print(f\"Vocabulary Size: {actual_vocab_size}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "294"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.get_word_index(\"pai\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'de': 0,\n",
       " 'a': 1,\n",
       " 'e': 2,\n",
       " 'o': 3,\n",
       " 'em': 4,\n",
       " 'do': 5,\n",
       " 'da': 6,\n",
       " 'que': 7,\n",
       " 'um': 8,\n",
       " 'uma': 9,\n",
       " 'no': 10,\n",
       " 'com': 11,\n",
       " 'para': 12,\n",
       " 'na': 13,\n",
       " 'é': 14,\n",
       " 'foi': 15,\n",
       " 'por': 16,\n",
       " 'os': 17,\n",
       " 'como': 18,\n",
       " 'as': 19,\n",
       " 'dos': 20,\n",
       " '[BEG]': 21,\n",
       " 'se': 22,\n",
       " 'ao': 23,\n",
       " 'mais': 24,\n",
       " 'sua': 25,\n",
       " 'seu': 26,\n",
       " 'das': 27,\n",
       " 'não': 28,\n",
       " 'são': 29,\n",
       " 'ou': 30,\n",
       " 'à': 31,\n",
       " 'também': 32,\n",
       " 'pela': 33,\n",
       " 'pelo': 34,\n",
       " 'ele': 35,\n",
       " 'entre': 36,\n",
       " 'ser': 37,\n",
       " 'era': 38,\n",
       " 'mas': 39,\n",
       " 'nos': 40,\n",
       " 'anos': 41,\n",
       " '[END]': 42,\n",
       " 'foram': 43,\n",
       " 'durante': 44,\n",
       " 'asteroide': 45,\n",
       " 'dia': 46,\n",
       " 'até': 47,\n",
       " 'nas': 48,\n",
       " 'sobre': 49,\n",
       " 'seus': 50,\n",
       " 'quando': 51,\n",
       " 'onde': 52,\n",
       " 'depois': 53,\n",
       " 'cidade': 54,\n",
       " 'após': 55,\n",
       " 'este': 56,\n",
       " 'primeira': 57,\n",
       " 'sendo': 58,\n",
       " 'grande': 59,\n",
       " 'ano': 60,\n",
       " 'parte': 61,\n",
       " 'tem': 62,\n",
       " 'dois': 63,\n",
       " 'primeiro': 64,\n",
       " 'mesmo': 65,\n",
       " 'suas': 66,\n",
       " 'aos': 67,\n",
       " 'ela': 68,\n",
       " 'ainda': 69,\n",
       " 'principal': 70,\n",
       " 'brasil': 71,\n",
       " 'história': 72,\n",
       " '2000': 73,\n",
       " 'the': 74,\n",
       " 'rio': 75,\n",
       " 'outros': 76,\n",
       " 'três': 77,\n",
       " 'possui': 78,\n",
       " 'nome': 79,\n",
       " 'vez': 80,\n",
       " 'final': 81,\n",
       " 'já': 82,\n",
       " 'além': 83,\n",
       " 'família': 84,\n",
       " 'grupo': 85,\n",
       " 'pode': 86,\n",
       " 'está': 87,\n",
       " 'maior': 88,\n",
       " 'apenas': 89,\n",
       " 'janeiro': 90,\n",
       " 'muito': 91,\n",
       " 'estado': 92,\n",
       " 'segundo': 93,\n",
       " 'às': 94,\n",
       " 'região': 95,\n",
       " 'então': 96,\n",
       " 'tempo': 97,\n",
       " 'área': 98,\n",
       " 'nova': 99,\n",
       " 'duas': 100,\n",
       " 'forma': 101,\n",
       " 'desde': 102,\n",
       " 'sul': 103,\n",
       " '1': 104,\n",
       " 'guerra': 105,\n",
       " 'esta': 106,\n",
       " 'contra': 107,\n",
       " 'assim': 108,\n",
       " 'ter': 109,\n",
       " 'sistema': 110,\n",
       " 'segunda': 111,\n",
       " 'sido': 112,\n",
       " 'antes': 113,\n",
       " 'álbum': 114,\n",
       " 'mundo': 115,\n",
       " 'alguns': 116,\n",
       " 'sem': 117,\n",
       " 'enquanto': 118,\n",
       " 'todos': 119,\n",
       " 'qual': 120,\n",
       " '2': 121,\n",
       " 'eles': 122,\n",
       " 'música': 123,\n",
       " 'paulo': 124,\n",
       " 'tinha': 125,\n",
       " 'outras': 126,\n",
       " 'pelos': 127,\n",
       " 'jogos': 128,\n",
       " 'governo': 129,\n",
       " 'agosto': 130,\n",
       " 'estados': 131,\n",
       " 'teve': 132,\n",
       " 'país': 133,\n",
       " 'cada': 134,\n",
       " 'vida': 135,\n",
       " 'nacional': 136,\n",
       " 'série': 137,\n",
       " 'século': 138,\n",
       " '1999': 139,\n",
       " 'setembro': 140,\n",
       " 'norte': 141,\n",
       " 'carreira': 142,\n",
       " 'partir': 143,\n",
       " 'mundial': 144,\n",
       " 'isso': 145,\n",
       " 'freguesia': 146,\n",
       " 'número': 147,\n",
       " 'filme': 148,\n",
       " 'descoberto': 149,\n",
       " 'julho': 150,\n",
       " 'março': 151,\n",
       " 'eram': 152,\n",
       " 'outubro': 153,\n",
       " 'novo': 154,\n",
       " 'quatro': 155,\n",
       " 'maio': 156,\n",
       " '3': 157,\n",
       " 'bem': 158,\n",
       " 'tendo': 159,\n",
       " 'casa': 160,\n",
       " 'início': 161,\n",
       " 'inclinação': 162,\n",
       " 'pessoas': 163,\n",
       " 'cintura': 164,\n",
       " 'excentricidade': 165,\n",
       " 'escola': 166,\n",
       " 'estava': 167,\n",
       " 'unidos': 168,\n",
       " 'abril': 169,\n",
       " 'banda': 170,\n",
       " 'novembro': 171,\n",
       " 'devido': 172,\n",
       " 'época': 173,\n",
       " '1998': 174,\n",
       " 'fez': 175,\n",
       " 'população': 176,\n",
       " 'temporada': 177,\n",
       " 'cerca': 178,\n",
       " 'vezes': 179,\n",
       " 'há': 180,\n",
       " 'vários': 181,\n",
       " 'universidade': 182,\n",
       " 'podem': 183,\n",
       " 'lugar': 184,\n",
       " 'junho': 185,\n",
       " 'sob': 186,\n",
       " 'conhecido': 187,\n",
       " 'dias': 188,\n",
       " 'através': 189,\n",
       " 'período': 190,\n",
       " 'algumas': 191,\n",
       " 'trabalho': 192,\n",
       " 'dezembro': 193,\n",
       " 'distrito': 194,\n",
       " 'filho': 195,\n",
       " 'município': 196,\n",
       " 'vila': 197,\n",
       " 'centro': 198,\n",
       " '10': 199,\n",
       " 'começou': 200,\n",
       " 'embora': 201,\n",
       " 'seguinte': 202,\n",
       " 'havia': 203,\n",
       " 'entanto': 204,\n",
       " 'of': 205,\n",
       " 'jogo': 206,\n",
       " 'ilha': 207,\n",
       " 'outro': 208,\n",
       " 'presidente': 209,\n",
       " 'passou': 210,\n",
       " 'muitos': 211,\n",
       " 'acordo': 212,\n",
       " 'estão': 213,\n",
       " '5': 214,\n",
       " 'ordem': 215,\n",
       " 'melhor': 216,\n",
       " 'fevereiro': 217,\n",
       " '–': 218,\n",
       " 'brasileiro': 219,\n",
       " '4': 220,\n",
       " 'espécies': 221,\n",
       " 'todo': 222,\n",
       " 'igreja': 223,\n",
       " 'linear': 224,\n",
       " 'exemplo': 225,\n",
       " 'tipo': 226,\n",
       " 'espécie': 227,\n",
       " 'várias': 228,\n",
       " 'década': 229,\n",
       " 'muitas': 230,\n",
       " 'meio': 231,\n",
       " 'título': 232,\n",
       " 'países': 233,\n",
       " 'tarde': 234,\n",
       " 'futebol': 235,\n",
       " 'campeonato': 236,\n",
       " 'produção': 237,\n",
       " 'todas': 238,\n",
       " 'tropical': 239,\n",
       " 'apesar': 240,\n",
       " 'equipe': 241,\n",
       " 'local': 242,\n",
       " 'morte': 243,\n",
       " 'joão': 244,\n",
       " 'base': 245,\n",
       " 'clube': 246,\n",
       " '20': 247,\n",
       " 'milhões': 248,\n",
       " 'essa': 249,\n",
       " 'grandes': 250,\n",
       " 'incluindo': 251,\n",
       " '12': 252,\n",
       " 'direito': 253,\n",
       " 'lado': 254,\n",
       " 'fim': 255,\n",
       " 'lançado': 256,\n",
       " 'recebeu': 257,\n",
       " 'desenvolvimento': 258,\n",
       " 'internacional': 259,\n",
       " 'gênero': 260,\n",
       " 'canção': 261,\n",
       " 'santa': 262,\n",
       " 'maria': 263,\n",
       " 'disso': 264,\n",
       " 'longo': 265,\n",
       " '2002': 266,\n",
       " 'política': 267,\n",
       " 'livro': 268,\n",
       " 'principais': 269,\n",
       " 'josé': 270,\n",
       " 'hoje': 271,\n",
       " '15': 272,\n",
       " 'cinco': 273,\n",
       " 'terra': 274,\n",
       " 'programa': 275,\n",
       " 'portugal': 276,\n",
       " 'seja': 277,\n",
       " 'geral': 278,\n",
       " 'sucesso': 279,\n",
       " 'pelas': 280,\n",
       " 'esse': 281,\n",
       " 'menos': 282,\n",
       " 'outra': 283,\n",
       " 'maioria': 284,\n",
       " 'numa': 285,\n",
       " 'qualquer': 286,\n",
       " '6': 287,\n",
       " 'pouco': 288,\n",
       " 'pois': 289,\n",
       " 'rei': 290,\n",
       " 'brasileira': 291,\n",
       " 'ficou': 292,\n",
       " 'volta': 293,\n",
       " 'pai': 294,\n",
       " 'linha': 295,\n",
       " 'sede': 296,\n",
       " '—': 297,\n",
       " 'império': 298,\n",
       " '30': 299,\n",
       " 'desta': 300,\n",
       " 'porém': 301,\n",
       " 'só': 302,\n",
       " 'atualmente': 303,\n",
       " 'fazer': 304,\n",
       " 'china': 305,\n",
       " 'dentro': 306,\n",
       " 'mesma': 307,\n",
       " 'caso': 308,\n",
       " 'obras': 309,\n",
       " 'uso': 310,\n",
       " 'projeto': 311,\n",
       " '2014': 312,\n",
       " 'geralmente': 313,\n",
       " 'frança': 314,\n",
       " 'quais': 315,\n",
       " 'copa': 316,\n",
       " 'num': 317,\n",
       " '25': 318,\n",
       " 'principalmente': 319,\n",
       " '7': 320,\n",
       " 'origem': 321,\n",
       " 'habitantes': 322,\n",
       " 'américa': 323,\n",
       " 'construção': 324,\n",
       " 'tornouse': 325,\n",
       " 'reino': 326,\n",
       " 'república': 327,\n",
       " '2007': 328,\n",
       " 'conhecida': 329,\n",
       " 'primeiros': 330,\n",
       " 'chamado': 331,\n",
       " 'partido': 332,\n",
       " 'quase': 333,\n",
       " '2013': 334,\n",
       " 'mil': 335,\n",
       " 'serviço': 336,\n",
       " 'público': 337,\n",
       " 'versão': 338,\n",
       " 'diferentes': 339,\n",
       " '1997': 340,\n",
       " 'total': 341,\n",
       " '2008': 342,\n",
       " '8': 343,\n",
       " 'seguintes': 344,\n",
       " 'campo': 345,\n",
       " '24': 346,\n",
       " 'província': 347,\n",
       " 'central': 348,\n",
       " 'divisão': 349,\n",
       " 'posição': 350,\n",
       " 'porto': 351,\n",
       " '2012': 352,\n",
       " 'atual': 353,\n",
       " 'federal': 354,\n",
       " 'militar': 355,\n",
       " 'seria': 356,\n",
       " 'capital': 357,\n",
       " 'pertencente': 358,\n",
       " 'lei': 359,\n",
       " 'água': 360,\n",
       " 'obra': 361,\n",
       " '2010': 362,\n",
       " 'tempestade': 363,\n",
       " 'sempre': 364,\n",
       " 'processo': 365,\n",
       " 'costa': 366,\n",
       " 'oficial': 367,\n",
       " '2011': 368,\n",
       " '2006': 369,\n",
       " 'i': 370,\n",
       " '13': 371,\n",
       " 'importante': 372,\n",
       " 'bulbophyllum': 373,\n",
       " 'edição': 374,\n",
       " 'poder': 375,\n",
       " '2009': 376,\n",
       " 'toda': 377,\n",
       " 'sociedade': 378,\n",
       " 'têm': 379,\n",
       " 'áreas': 380,\n",
       " 'junto': 381,\n",
       " 'movimento': 382,\n",
       " 'tornou': 383,\n",
       " 'antigo': 384,\n",
       " 'relação': 385,\n",
       " '9': 386,\n",
       " 'chegou': 387,\n",
       " '14': 388,\n",
       " 'alemão': 389,\n",
       " 'metros': 390,\n",
       " 'arte': 391,\n",
       " '2003': 392,\n",
       " 'tanto': 393,\n",
       " 'portuguesa': 394,\n",
       " 'empresa': 395,\n",
       " '16': 396,\n",
       " 'social': 397,\n",
       " 'papel': 398,\n",
       " 'seis': 399,\n",
       " '18': 400,\n",
       " 'chamada': 401,\n",
       " 'último': 402,\n",
       " '11': 403,\n",
       " 'ponto': 404,\n",
       " 'jogador': 405,\n",
       " 'la': 406,\n",
       " 'alemanha': 407,\n",
       " 'logo': 408,\n",
       " 'd': 409,\n",
       " 'luta': 410,\n",
       " '2015': 411,\n",
       " 'lançamento': 412,\n",
       " 'membros': 413,\n",
       " 'europa': 414,\n",
       " 'single': 415,\n",
       " 'fora': 416,\n",
       " 'conta': 417,\n",
       " 'museu': 418,\n",
       " 'ii': 419,\n",
       " 'ouro': 420,\n",
       " 'conjunto': 421,\n",
       " 'and': 422,\n",
       " 'idade': 423,\n",
       " 'novamente': 424,\n",
       " 'ataque': 425,\n",
       " 'real': 426,\n",
       " 'vitória': 427,\n",
       " 'grupos': 428,\n",
       " 'participou': 429,\n",
       " '23': 430,\n",
       " 'território': 431,\n",
       " 'deste': 432,\n",
       " 'exército': 433,\n",
       " 'mar': 434,\n",
       " 'nível': 435,\n",
       " 'localizada': 436,\n",
       " '2001': 437,\n",
       " 'antiga': 438,\n",
       " 'carlos': 439,\n",
       " 'corpo': 440,\n",
       " 'in': 441,\n",
       " 'pedro': 442,\n",
       " 'seleção': 443,\n",
       " '2004': 444,\n",
       " 'cultura': 445,\n",
       " 'próprio': 446,\n",
       " 'localizado': 447,\n",
       " 'união': 448,\n",
       " 'quem': 449,\n",
       " 'formação': 450,\n",
       " 'popular': 451,\n",
       " '17': 452,\n",
       " '21': 453,\n",
       " 'disco': 454,\n",
       " 'forte': 455,\n",
       " 'quanto': 456,\n",
       " 'estação': 457,\n",
       " 'usado': 458,\n",
       " 'diversas': 459,\n",
       " 'fase': 460,\n",
       " 'único': 461,\n",
       " 'posteriormente': 462,\n",
       " 'economia': 463,\n",
       " 'tal': 464,\n",
       " 'energia': 465,\n",
       " 'municipal': 466,\n",
       " 'paris': 467,\n",
       " 'média': 468,\n",
       " 'criação': 469,\n",
       " 'última': 470,\n",
       " '26': 471,\n",
       " '2016': 472,\n",
       " 'força': 473,\n",
       " 'francês': 474,\n",
       " '2005': 475,\n",
       " 'lista': 476,\n",
       " '2018': 477,\n",
       " 'pontos': 478,\n",
       " 'rede': 479,\n",
       " 'eleito': 480,\n",
       " '2022': 481,\n",
       " 'faz': 482,\n",
       " '19': 483,\n",
       " 'filha': 484,\n",
       " 'considerado': 485,\n",
       " 'termo': 486,\n",
       " '22': 487,\n",
       " 'm': 488,\n",
       " 'km': 489,\n",
       " '28': 490,\n",
       " 'categoria': 491,\n",
       " 'john': 492,\n",
       " 'português': 493,\n",
       " 'meses': 494,\n",
       " 'estudos': 495,\n",
       " 'terceira': 496,\n",
       " 'político': 497,\n",
       " 'estavam': 498,\n",
       " 'espaço': 499,\n",
       " 'francisco': 500,\n",
       " 'torneio': 501,\n",
       " 'características': 502,\n",
       " 'estilo': 503,\n",
       " 'maiores': 504,\n",
       " 'superior': 505,\n",
       " 'plantas': 506,\n",
       " 'neste': 507,\n",
       " 'terceiro': 508,\n",
       " 'membro': 509,\n",
       " 'biografia': 510,\n",
       " 'existem': 511,\n",
       " 'homem': 512,\n",
       " 'mãe': 513,\n",
       " 'cargo': 514,\n",
       " 'francesa': 515,\n",
       " 'porque': 516,\n",
       " '100': 517,\n",
       " 'revista': 518,\n",
       " 'oeste': 519,\n",
       " 'frente': 520,\n",
       " '2021': 521,\n",
       " 'comum': 522,\n",
       " 'operações': 523,\n",
       " 'diversos': 524,\n",
       " 'dados': 525,\n",
       " 'deu': 526,\n",
       " 'ganhou': 527,\n",
       " 'sistemas': 528,\n",
       " 'disse': 529,\n",
       " 'câmara': 530,\n",
       " 'socorro': 531,\n",
       " 'língua': 532,\n",
       " 'cruz': 533,\n",
       " 'departamento': 534,\n",
       " 'televisão': 535,\n",
       " 'única': 536,\n",
       " 'leste': 537,\n",
       " 'valor': 538,\n",
       " 'campeão': 539,\n",
       " 'inglês': 540,\n",
       " 'esteve': 541,\n",
       " 'original': 542,\n",
       " 'educação': 543,\n",
       " 'mulheres': 544,\n",
       " 'simples': 545,\n",
       " 'lhe': 546,\n",
       " 'profissional': 547,\n",
       " 'estádio': 548,\n",
       " 'rua': 549,\n",
       " 'agora': 550,\n",
       " 'deve': 551,\n",
       " 'conseguiu': 552,\n",
       " 'roma': 553,\n",
       " 'modo': 554,\n",
       " 'cidades': 555,\n",
       " 'ac': 556,\n",
       " 'tufão': 557,\n",
       " 'filhos': 558,\n",
       " 'depressão': 559,\n",
       " 'partida': 560,\n",
       " 'saúde': 561,\n",
       " 'km²': 562,\n",
       " 'prêmio': 563,\n",
       " 'ensino': 564,\n",
       " 'liga': 565,\n",
       " 'resultado': 566,\n",
       " 'musical': 567,\n",
       " 'regiões': 568,\n",
       " 'ambos': 569,\n",
       " '2019': 570,\n",
       " 'locais': 571,\n",
       " 'bairro': 572,\n",
       " 'possível': 573,\n",
       " 'festival': 574,\n",
       " 'sete': 575,\n",
       " 'estes': 576,\n",
       " 'importantes': 577,\n",
       " 'dez': 578,\n",
       " 'apresenta': 579,\n",
       " 'time': 580,\n",
       " 'distribuição': 581,\n",
       " 'alta': 582,\n",
       " 'santo': 583,\n",
       " 'natural': 584,\n",
       " 'conquistou': 585,\n",
       " 'feito': 586,\n",
       " '2017': 587,\n",
       " '27': 588,\n",
       " 'japão': 589,\n",
       " 'direção': 590,\n",
       " 'lisboa': 591,\n",
       " 'causa': 592,\n",
       " 'classe': 593,\n",
       " 'jornal': 594,\n",
       " 'modelo': 595,\n",
       " 'organização': 596,\n",
       " 'acabou': 597,\n",
       " 'professor': 598,\n",
       " 'nasceu': 599,\n",
       " 'mulher': 600,\n",
       " '1996': 601,\n",
       " 'fato': 602,\n",
       " 'parque': 603,\n",
       " '1990': 604,\n",
       " 'tais': 605,\n",
       " 'apoio': 606,\n",
       " '29': 607,\n",
       " 'b': 608,\n",
       " 'serviços': 609,\n",
       " 'nesta': 610,\n",
       " 'cantora': 611,\n",
       " 'comércio': 612,\n",
       " 'presença': 613,\n",
       " 'controle': 614,\n",
       " 'direitos': 615,\n",
       " 'problemas': 616,\n",
       " 'elas': 617,\n",
       " 'batalha': 618,\n",
       " 'nomes': 619,\n",
       " 'novas': 620,\n",
       " 'solo': 621,\n",
       " 'tv': 622,\n",
       " 'capacidade': 623,\n",
       " 'evento': 624,\n",
       " 'nunca': 625,\n",
       " 'homens': 626,\n",
       " 'atividades': 627,\n",
       " 'momento': 628,\n",
       " 'própria': 629,\n",
       " 'morreu': 630,\n",
       " 'estudo': 631,\n",
       " 'especialmente': 632,\n",
       " 'nesse': 633,\n",
       " 'x': 634,\n",
       " 'escreveu': 635,\n",
       " 'função': 636,\n",
       " 'data': 637,\n",
       " 'somente': 638,\n",
       " 'irmão': 639,\n",
       " 'seguida': 640,\n",
       " 'especial': 641,\n",
       " 'forças': 642,\n",
       " 'alto': 643,\n",
       " 'imperador': 644,\n",
       " 'pesquisa': 645,\n",
       " 'baixa': 646,\n",
       " 'escolas': 647,\n",
       " 'realizada': 648,\n",
       " 'teoria': 649,\n",
       " 'teria': 650,\n",
       " 'curso': 651,\n",
       " 'levou': 652,\n",
       " 'atuou': 653,\n",
       " 'partes': 654,\n",
       " 'instituto': 655,\n",
       " 'silva': 656,\n",
       " 'diretor': 657,\n",
       " 'isto': 658,\n",
       " 'portanto': 659,\n",
       " 'fundação': 660,\n",
       " 'associação': 661,\n",
       " 'dinastia': 662,\n",
       " 'eu': 663,\n",
       " '1970': 664,\n",
       " 'acesso': 665,\n",
       " 'perto': 666,\n",
       " 'cultural': 667,\n",
       " 'administrativa': 668,\n",
       " 'estrutura': 669,\n",
       " 'competição': 670,\n",
       " 'crítica': 671,\n",
       " 'interior': 672,\n",
       " 'tenha': 673,\n",
       " 'concelho': 674,\n",
       " 'via': 675,\n",
       " 'nº': 676,\n",
       " 'londres': 677,\n",
       " 'tinham': 678,\n",
       " 'fosse': 679,\n",
       " 'novos': 680,\n",
       " 'responsável': 681,\n",
       " 'criada': 682,\n",
       " 'itália': 683,\n",
       " 'livre': 684,\n",
       " 'horas': 685,\n",
       " 'juntamente': 686,\n",
       " 'casos': 687,\n",
       " 'dessa': 688,\n",
       " 'teatro': 689,\n",
       " 'desse': 690,\n",
       " 'anterior': 691,\n",
       " 'áfrica': 692,\n",
       " 'unido': 693,\n",
       " 'objetivo': 694,\n",
       " '1980': 695,\n",
       " 'deixou': 696,\n",
       " 'zona': 697,\n",
       " 'atingiu': 698,\n",
       " 'relações': 699,\n",
       " 'noite': 700,\n",
       " 'menor': 701,\n",
       " 'comunidade': 702,\n",
       " 'comando': 703,\n",
       " 'estreia': 704,\n",
       " 'perdeu': 705,\n",
       " 'verão': 706,\n",
       " 'ocorreu': 707,\n",
       " 'entretanto': 708,\n",
       " 'voltou': 709,\n",
       " 'próximo': 710,\n",
       " 'realizado': 711,\n",
       " 'empresas': 712,\n",
       " 'jovem': 713,\n",
       " 's': 714,\n",
       " 'esses': 715,\n",
       " 'ilhas': 716,\n",
       " 'conselho': 717,\n",
       " 'campanha': 718,\n",
       " 'terras': 719,\n",
       " '1995': 720,\n",
       " 'segurança': 721,\n",
       " 'ocidental': 722,\n",
       " 'bastante': 723,\n",
       " 'lançou': 724,\n",
       " 'altura': 725,\n",
       " 'rádio': 726,\n",
       " 'venceu': 727,\n",
       " 'nomeado': 728,\n",
       " 'santos': 729,\n",
       " 'melhores': 730,\n",
       " 'índia': 731,\n",
       " 'rodada': 732,\n",
       " 'cinema': 733,\n",
       " 'condições': 734,\n",
       " '31': 735,\n",
       " '50': 736,\n",
       " 'criado': 737,\n",
       " 'olímpicos': 738,\n",
       " 'mercado': 739,\n",
       " 'médio': 740,\n",
       " 'artista': 741,\n",
       " 'fica': 742,\n",
       " 'oito': 743,\n",
       " 'governador': 744,\n",
       " 'essas': 745,\n",
       " 'companhia': 746,\n",
       " 'tão': 747,\n",
       " 'inglaterra': 748,\n",
       " 'estas': 749,\n",
       " 'eventos': 750,\n",
       " 'participação': 751,\n",
       " 'escrita': 752,\n",
       " 'luz': 753,\n",
       " 'filmes': 754,\n",
       " 'ar': 755,\n",
       " 'descrita': 756,\n",
       " 'músicas': 757,\n",
       " 'histórico': 758,\n",
       " 'densidade': 759,\n",
       " 'esposa': 760,\n",
       " 'administração': 761,\n",
       " 'espanha': 762,\n",
       " 'pessoa': 763,\n",
       " '1º': 764,\n",
       " 'minas': 765,\n",
       " 'sociais': 766,\n",
       " 'células': 767,\n",
       " 'semana': 768,\n",
       " 'xix': 769,\n",
       " 'rock': 770,\n",
       " 'primeiras': 771,\n",
       " 'importância': 772,\n",
       " 'episódio': 773,\n",
       " 'ferreira': 774,\n",
       " 'entrou': 775,\n",
       " 'castelo': 776,\n",
       " 'show': 777,\n",
       " 'civil': 778,\n",
       " 'livros': 779,\n",
       " 'famílias': 780,\n",
       " 'san': 781,\n",
       " 'unidade': 782,\n",
       " 'fazendo': 783,\n",
       " 'minutos': 784,\n",
       " 'canal': 785,\n",
       " 'deus': 786,\n",
       " 'produtos': 787,\n",
       " 'si': 788,\n",
       " 'terminou': 789,\n",
       " 'transporte': 790,\n",
       " 'inicialmente': 791,\n",
       " 'existe': 792,\n",
       " 'oficiais': 793,\n",
       " 'faixa': 794,\n",
       " 'vídeo': 795,\n",
       " 'baseado': 796,\n",
       " '2020': 797,\n",
       " 'ministro': 798,\n",
       " 'tudo': 799,\n",
       " 'medida': 800,\n",
       " '1994': 801,\n",
       " 'feminino': 802,\n",
       " 'estúdio': 803,\n",
       " 'crescimento': 804,\n",
       " 'edifício': 805,\n",
       " 'personagem': 806,\n",
       " 'pública': 807,\n",
       " 'ministério': 808,\n",
       " 'pequena': 809,\n",
       " 'artistas': 810,\n",
       " 'frequentemente': 811,\n",
       " 'medalha': 812,\n",
       " 'contém': 813,\n",
       " 'incluem': 814,\n",
       " 'estadual': 815,\n",
       " 'influência': 816,\n",
       " 'mês': 817,\n",
       " 'aproximadamente': 818,\n",
       " 'rapidamente': 819,\n",
       " 'presente': 820,\n",
       " '2023': 821,\n",
       " 'marinha': 822,\n",
       " 'prática': 823,\n",
       " 'elementos': 824,\n",
       " 'gerais': 825,\n",
       " 'continuou': 826,\n",
       " 'estrelas': 827,\n",
       " 'classificação': 828,\n",
       " 'méxico': 829,\n",
       " 'quarto': 830,\n",
       " 'comercial': 831,\n",
       " 'eleições': 832,\n",
       " 'tipos': 833,\n",
       " 'conde': 834,\n",
       " 'vista': 835,\n",
       " 'general': 836,\n",
       " 'populacional': 837,\n",
       " 'trabalhos': 838,\n",
       " 'inclui': 839,\n",
       " 'príncipe': 840,\n",
       " 'defesa': 841,\n",
       " 'canções': 842,\n",
       " 'poderia': 843,\n",
       " 'deputado': 844,\n",
       " 'serem': 845,\n",
       " 'vivo': 846,\n",
       " 'feita': 847,\n",
       " 'povo': 848,\n",
       " 'anunciou': 849,\n",
       " 'caminho': 850,\n",
       " 'composto': 851,\n",
       " 'maneira': 852,\n",
       " 'crianças': 853,\n",
       " 'panamericanos': 854,\n",
       " 'considerada': 855,\n",
       " 'termos': 856,\n",
       " 'nem': 857,\n",
       " 'estrada': 858,\n",
       " 'ciências': 859,\n",
       " 'normalmente': 860,\n",
       " 'peças': 861,\n",
       " 'vale': 862,\n",
       " 'publicado': 863,\n",
       " 'amor': 864,\n",
       " 'for': 865,\n",
       " 'usada': 866,\n",
       " 'nossa': 867,\n",
       " 'serviu': 868,\n",
       " 'boa': 869,\n",
       " 'americano': 870,\n",
       " 'paulista': 871,\n",
       " 'jardim': 872,\n",
       " 'autor': 873,\n",
       " 'material': 874,\n",
       " 'líder': 875,\n",
       " '1993': 876,\n",
       " 'significa': 877,\n",
       " 'pessoal': 878,\n",
       " 'indústria': 879,\n",
       " 'luís': 880,\n",
       " 'animais': 881,\n",
       " 'houve': 882,\n",
       " '0': 883,\n",
       " 'prova': 884,\n",
       " 'homenagem': 885,\n",
       " 'c': 886,\n",
       " 'ideia': 887,\n",
       " 'flores': 888,\n",
       " 'kriegsmarine': 889,\n",
       " 'militares': 890,\n",
       " 'estar': 891,\n",
       " 'palácio': 892,\n",
       " 'freguesias': 893,\n",
       " 'usando': 894,\n",
       " 'dupla': 895,\n",
       " 'acima': 896,\n",
       " 'lá': 897,\n",
       " 'votos': 898,\n",
       " 'iniciou': 899,\n",
       " 'ocorre': 900,\n",
       " 'humanos': 901,\n",
       " 'plano': 902,\n",
       " '1960': 903,\n",
       " 'campos': 904,\n",
       " 'manuel': 905,\n",
       " 'us': 906,\n",
       " 'oficialmente': 907,\n",
       " 'estreou': 908,\n",
       " 'reforma': 909,\n",
       " 'argentina': 910,\n",
       " 'hospital': 911,\n",
       " 'interesse': 912,\n",
       " 'baixo': 913,\n",
       " 'atividade': 914,\n",
       " 'pop': 915,\n",
       " 'títulos': 916,\n",
       " 'contrato': 917,\n",
       " 'artes': 918,\n",
       " 'industrial': 919,\n",
       " 'unidades': 920,\n",
       " 'xx': 921,\n",
       " 'originalmente': 922,\n",
       " 'ferro': 923,\n",
       " 'fundada': 924,\n",
       " 'senhora': 925,\n",
       " 'masculino': 926,\n",
       " 'equipes': 927,\n",
       " 'aumento': 928,\n",
       " 'austrália': 929,\n",
       " 'recursos': 930,\n",
       " 'utilizado': 931,\n",
       " 'resultados': 932,\n",
       " 'escrito': 933,\n",
       " 'gols': 934,\n",
       " 'construído': 935,\n",
       " 'samba': 936,\n",
       " 'vai': 937,\n",
       " 'algum': 938,\n",
       " '1992': 939,\n",
       " 'revolução': 940,\n",
       " 'ação': 941,\n",
       " 'ver': 942,\n",
       " 'pequeno': 943,\n",
       " 'finalmente': 944,\n",
       " 'ciência': 945,\n",
       " 'composta': 946,\n",
       " 'formas': 947,\n",
       " 'letras': 948,\n",
       " 'p': 949,\n",
       " 'políticas': 950,\n",
       " 'deles': 951,\n",
       " 'iii': 952,\n",
       " 'italiano': 953,\n",
       " 'dar': 954,\n",
       " 'disputa': 955,\n",
       " 'tecnologia': 956,\n",
       " 'casas': 957,\n",
       " 'natureza': 958,\n",
       " 'cuja': 959,\n",
       " 'oliveira': 960,\n",
       " 'conceito': 961,\n",
       " 'jogadores': 962,\n",
       " 'programas': 963,\n",
       " 'padrão': 964,\n",
       " '40': 965,\n",
       " 'conhecimento': 966,\n",
       " 'new': 967,\n",
       " 'fonte': 968,\n",
       " 'tiveram': 969,\n",
       " 'york': 970,\n",
       " 'prata': 971,\n",
       " 'informações': 972,\n",
       " 'pacífico': 973,\n",
       " 'ambiente': 974,\n",
       " 'situação': 975,\n",
       " 'possuem': 976,\n",
       " 'fernando': 977,\n",
       " 'tamanho': 978,\n",
       " 'navio': 979,\n",
       " 'qing': 980,\n",
       " 'doença': 981,\n",
       " 'referência': 982,\n",
       " 'destaque': 983,\n",
       " 'robert': 984,\n",
       " 'marcou': 985,\n",
       " 'longa': 986,\n",
       " 'bom': 987,\n",
       " 'comandante': 988,\n",
       " 'nessa': 989,\n",
       " 'formar': 990,\n",
       " 'trabalhar': 991,\n",
       " 'obteve': 992,\n",
       " 'branco': 993,\n",
       " 'ásia': 994,\n",
       " 'chefe': 995,\n",
       " 'operação': 996,\n",
       " 'missão': 997,\n",
       " 'contudo': 998,\n",
       " 'bahia': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_to_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NeuralProbabilisticLanguageModel(\n",
      "  (embeddings): Embedding(10000, 100)\n",
      "  (hidden): Linear(in_features=300, out_features=128, bias=True)\n",
      "  (output): Linear(in_features=128, out_features=10000, bias=True)\n",
      "  (dropout): Dropout(p=0.3, inplace=False)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model\n",
    "model = NeuralProbabilisticLanguageModel(\n",
    "    vocab_size=actual_vocab_size,\n",
    "    embedding_dim=embedding_dim,\n",
    "    context_size=n,  # For trigram, context_size=2\n",
    "    hidden_dim=hidden_dim\n",
    ").to(device)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "# (Optional) Learning rate scheduler\n",
    "# scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def collate_wrapper(batch):\n",
    "    ngrams, targets = batch\n",
    "    return collate_fn((ngrams, targets), word_to_index, model.embeddings)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, dataloader, word_to_index, context_size, device):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    total_loss = 0.0\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in dataloader:\n",
    "            ngrams, targets = batch\n",
    "            context_tensor, target_tensor = collate_wrapper((ngrams, targets))\n",
    "            context_tensor = context_tensor.to(device)\n",
    "            target_tensor = target_tensor.to(device)\n",
    "\n",
    "            outputs = model(context_tensor)\n",
    "            loss = criterion(outputs, target_tensor)\n",
    "            total_loss += loss.item()\n",
    "    \n",
    "    avg_loss = total_loss / len(dataloader)\n",
    "    return avg_loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subtract_and_add(word1, word2, word3):\n",
    "    index1 = word_to_index.get(word1)\n",
    "    index2 = word_to_index.get(word2)\n",
    "    index3 = word_to_index.get(word3)\n",
    "    \n",
    "    if index1 is None or index2 is None or index3 is None:\n",
    "        print(f\"One or more words '{word1}', '{word2}', or '{word3}' are not in the vocabulary.\")\n",
    "        return\n",
    "    \n",
    "    # Get embeddings for the words\n",
    "    embedding1 = model.embeddings(torch.tensor([index1]).to(device)).squeeze(0)\n",
    "    embedding2 = model.embeddings(torch.tensor([index2]).to(device)).squeeze(0)\n",
    "    embedding3 = model.embeddings(torch.tensor([index3]).to(device)).squeeze(0)\n",
    "    \n",
    "    # Perform the operation: word1 - word2 + word3\n",
    "    result_vector = embedding1 - embedding2 + embedding3\n",
    "    \n",
    "    # List to store similarity scores for each word\n",
    "    similarity_list = []\n",
    "    \n",
    "    for word, idx in word_to_index.items():\n",
    "        word_embedding = model.embeddings(torch.tensor([idx]).to(device)).squeeze(0)\n",
    "        similarity = F.cosine_similarity(result_vector, word_embedding, dim=0).item()\n",
    "        similarity_list.append((word, similarity))\n",
    "    \n",
    "    # Sort the list by similarity in descending order\n",
    "    similarity_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Print the top 5 most similar words\n",
    "    print(f\"The 5 most similar words to the result of '{word1} - {word2} + {word3}' are:\")\n",
    "    for word, similarity in similarity_list[:5]:\n",
    "        print(f\"'{word}' with similarity {similarity:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Starting Epoch 1/10 ---\n",
      "Total Batches in Epoch 1: 6697\n",
      "Epoch [1/10], Batch [500/6697], Avg Interval Loss: 6.4542, Batch Time: 0.01s\n",
      "Epoch [1/10], Batch [1000/6697], Avg Interval Loss: 5.8249, Batch Time: 0.01s\n",
      "Epoch [1/10], Batch [1500/6697], Avg Interval Loss: 5.6239, Batch Time: 0.01s\n",
      "Epoch [1/10], Batch [2000/6697], Avg Interval Loss: 5.5011, Batch Time: 0.01s\n",
      "Epoch [1/10], Batch [2500/6697], Avg Interval Loss: 5.4305, Batch Time: 0.01s\n",
      "Epoch [1/10], Batch [3000/6697], Avg Interval Loss: 5.3624, Batch Time: 0.01s\n",
      "Epoch [1/10], Batch [3500/6697], Avg Interval Loss: 5.3108, Batch Time: 0.01s\n",
      "Epoch [1/10], Batch [4000/6697], Avg Interval Loss: 5.2827, Batch Time: 0.01s\n",
      "Epoch [1/10], Batch [4500/6697], Avg Interval Loss: 5.2232, Batch Time: 0.01s\n",
      "Epoch [1/10], Batch [5000/6697], Avg Interval Loss: 5.2065, Batch Time: 0.01s\n",
      "Epoch [1/10], Batch [5500/6697], Avg Interval Loss: 5.1910, Batch Time: 0.01s\n",
      "Epoch [1/10], Batch [6000/6697], Avg Interval Loss: 5.1608, Batch Time: 0.01s\n",
      "Epoch [1/10], Batch [6500/6697], Avg Interval Loss: 5.1316, Batch Time: 0.01s\n",
      "--- Epoch 1 Completed ---\n",
      "Average Training Loss for Epoch 1: 5.4300\n",
      "Epoch Duration: 105.30s\n",
      "Validation Loss after Epoch 1: 4.9350\n",
      "Validation Duration: 49.25s\n",
      "Best model updated and saved at Epoch 1 with Validation Loss: 4.9350\n",
      "One or both words 'cachorro' and 'gato' are not in the vocabulary.\n",
      "The word 'cachorro' is not in the vocabulary.\n",
      "\n",
      "--- Starting Epoch 2/10 ---\n",
      "Total Batches in Epoch 2: 6697\n",
      "Epoch [2/10], Batch [500/6697], Avg Interval Loss: 5.0662, Batch Time: 0.01s\n",
      "Epoch [2/10], Batch [1000/6697], Avg Interval Loss: 5.0482, Batch Time: 0.02s\n",
      "Epoch [2/10], Batch [1500/6697], Avg Interval Loss: 5.0434, Batch Time: 0.01s\n",
      "Epoch [2/10], Batch [2000/6697], Avg Interval Loss: 5.0327, Batch Time: 0.01s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Define the function to print the top 5 most similar words for \"cachorro\"\n",
    "def print_top_similar_rei():\n",
    "    word = \"rei\"\n",
    "    index = word_to_index.get(word)\n",
    "    if index is None:\n",
    "        print(f\"The word '{word}' is not in the vocabulary.\")\n",
    "        return\n",
    "    \n",
    "    # Get the embedding for \"cachorro\"\n",
    "    embedding = model.embeddings(torch.tensor([index]).to(device)).squeeze(0)\n",
    "    \n",
    "    # List to store similarity scores for each word\n",
    "    similarity_list = []\n",
    "    \n",
    "    # Compute cosine similarity between \"cachorro\" and each word's embedding\n",
    "    for other_word, idx in word_to_index.items():\n",
    "        other_embedding = model.embeddings(torch.tensor([idx]).to(device)).squeeze(0)\n",
    "        similarity = F.cosine_similarity(embedding, other_embedding, dim=0).item()\n",
    "        similarity_list.append((other_word, similarity))\n",
    "    \n",
    "    # Sort the list by similarity in descending order\n",
    "    similarity_list.sort(key=lambda x: x[1], reverse=True)\n",
    "    \n",
    "    # Print the top 5 most similar words\n",
    "    print(f\"\\nThe 5 most similar words to '{word}' are:\")\n",
    "    for other_word, similarity in similarity_list[:5]:\n",
    "        print(f\"'{other_word}' with similarity {similarity:.4f}\")\n",
    "\n",
    "# Training pipeline starts here\n",
    "model.train()\n",
    "best_val_loss = float('inf')\n",
    "\n",
    "for epoch in range(1, num_epochs + 1):\n",
    "    epoch_start_time = time.time()\n",
    "    running_loss = 0.0\n",
    "    epoch_loss = 0.0\n",
    "    batch_count = len(dataloader)\n",
    "\n",
    "    print(f\"\\n--- Starting Epoch {epoch}/{num_epochs} ---\")\n",
    "    print(f\"Total Batches in Epoch {epoch}: {batch_count}\")\n",
    "\n",
    "    for batch_idx, batch in enumerate(dataloader):\n",
    "        batch_start_time = time.time()\n",
    "        ngrams, targets = batch\n",
    "\n",
    "        context_tensor, target_tensor = collate_wrapper((ngrams, targets))\n",
    "        context_tensor = context_tensor.long().to(device)\n",
    "        target_tensor = target_tensor.to(device)\n",
    "        \n",
    "        # Forward pass\n",
    "        outputs = model(context_tensor)\n",
    "        loss = criterion(outputs, target_tensor)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=5)\n",
    "        optimizer.step()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "        running_loss += loss.item()\n",
    "        \n",
    "        batch_end_time = time.time()\n",
    "        batch_duration = batch_end_time - batch_start_time\n",
    "        \n",
    "        # Print intermediate stats every 500 batches\n",
    "        if (batch_idx + 1) % 500 == 0:\n",
    "            avg_interval_loss = running_loss / 500\n",
    "            print(f\"Epoch [{epoch}/{num_epochs}], Batch [{batch_idx+1}/{batch_count}], \"\n",
    "                  f\"Avg Interval Loss: {avg_interval_loss:.4f}, \"\n",
    "                  f\"Batch Time: {batch_duration:.2f}s\")\n",
    "            running_loss = 0.0\n",
    "\n",
    "    avg_train_loss = epoch_loss / batch_count if batch_count > 0 else 0\n",
    "    epoch_end_time = time.time()\n",
    "    epoch_duration = epoch_end_time - epoch_start_time\n",
    "\n",
    "    print(f\"--- Epoch {epoch} Completed ---\")\n",
    "    print(f\"Average Training Loss for Epoch {epoch}: {avg_train_loss:.4f}\")\n",
    "    print(f\"Epoch Duration: {epoch_duration:.2f}s\")\n",
    "\n",
    "    # Evaluate\n",
    "    model.eval()\n",
    "    val_start_time = time.time()\n",
    "    val_loss = evaluate_model(model, dataloader, word_to_index, context_size=n-1, device=device)\n",
    "    val_end_time = time.time()\n",
    "    val_duration = val_end_time - val_start_time\n",
    "    model.train()\n",
    "\n",
    "    print(f\"Validation Loss after Epoch {epoch}: {val_loss:.4f}\")\n",
    "    print(f\"Validation Duration: {val_duration:.2f}s\")\n",
    "\n",
    "    # Checkpoint\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        torch.save(model.state_dict(), \"best_neural_probabilistic_language_model.pth\")\n",
    "        print(f\"Best model updated and saved at Epoch {epoch} with Validation Loss: {val_loss:.4f}\")\n",
    "\n",
    "    # Cosine similarity calculation for 'rei' and 'mae'\n",
    "    rei_index = word_to_index.get(\"rei\")\n",
    "    rainha_index = word_to_index.get(\"rainha\")\n",
    "    if rei_index is not None and rainha_index is not None:\n",
    "        rei_embedding = model.embeddings(torch.tensor([rei_index]).to(device)).squeeze(0)\n",
    "        rainha_embedding = model.embeddings(torch.tensor([rainha_index]).to(device)).squeeze(0)\n",
    "        cosine_similarity = F.cosine_similarity(rei_embedding, rainha_embedding, dim=0)\n",
    "        print(f\"Cosine Similarity between 'rei' and 'rainha' after Epoch {epoch}: {cosine_similarity.item():.4f}\")\n",
    "    else:\n",
    "        print(\"One or both words 'rei' and 'rainha' are not in the vocabulary.\")\n",
    "\n",
    "    # Print the top 5 most similar words for \"rei\"\n",
    "    print_top_similar_rei()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# avião e carro\n",
    "# pai e mae"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "data_ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
